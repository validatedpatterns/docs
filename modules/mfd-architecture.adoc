:_content-type: CONCEPT
:imagesdir: ../../images

[id="overview-architecture"]
== Overview of the Architecture

Description of each component:

* *Data Set*: The dataset contains the data used for training and evaluating the model built in this tutorial. The dataset is sourced from the link:https://github.com/rh-aiservices-bu/fraud-detection/tree/main/data[github.com/rh-aiservices-bu/fraud-detection]
* *Kubeflow Pipeline*: The Kubeflow pipeline builds, trains, and uploads the model. The source for this pipeline is in the pattern repository at link:https://github.com/validatedpatterns/mlops-fraud-detection/blob/main/src/kubeflow-pipelines/small-model/train_upload_model.yaml[src/kubeflow-pipelines/small-model/train_upload_model.yaml]. Upon pattern installation, the system automatically runs this pipeline once to train the initial model.
* *S3 (Minio)*: Minio provides storage for the models and serves as the storage interface for the Kubeflow pipeline. While this pattern uses Minio for parity with the source tutorial, any S3-compatible storage solution is compatible.
* *Kserve Model Serving*: The pattern uses the Kserve model serving capabilities in Red Hat OpenShift AI (RHOAI) to serve models with an OpenVINO model server.
* *Application interface*: This interface runs predictions with the model. This pattern includes a visual interface (interactive application) built with Gradio that loads the model from Minio.

//figure 1 originally
.Overview of the solution reference architecture
image::mlops-fraud-detection/mfd-reference-architecture.png[link="/images/mlops-fraud-detection/mfd-reference-architecture.png"]

//figure 2 logical
//.Logical Architecture
//image::mlops-fraud-detection/mfd-logical-architecture.png[link="/images/mlops-fraud-detection/mfd-logical-architecture.png", width=940]

//figure 3 Schema
//.Data Flow Architecture
//image::mlops-fraud-detection/mfd-schema-dataflow.png[link="/images/mlops-fraud-detection/mfd-schema-dataflow.png", width=940]

[id="about-technology"]
== About the technology

The following technologies are used in this solution:

link:https://www.redhat.com/en/technologies/cloud-computing/openshift/try-it[Red Hat OpenShift Container Platform]::
An enterprise-ready Kubernetes container platform built for an open hybrid cloud strategy. It provides a consistent application platform to manage hybrid cloud, public cloud, and edge deployments. It delivers a complete application platform for both traditional and cloud-native applications, allowing them to run anywhere. OpenShift has a pre-configured, pre-installed, and self-updating monitoring stack that provides monitoring for core platform components. It also enables the use of external secret management systems, for example, HashiCorp Vault in this case, to securely add secrets into the OpenShift platform.

link:https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-ai[Red Hat OpenShift AI]::
Red Hat® OpenShift® AI is an AI-focused portfolio that provides tools to train, tune, serve, monitor, and manage AI/ML experiments and models on Red Hat OpenShift. Bring data scientists, developers, and IT together on a unified platform to deliver AI-enabled applications faster.

https://www.redhat.com/en/technologies/cloud-computing/openshift/try-it[Red Hat OpenShift GitOps]::
A declarative application continuous delivery tool for Kubernetes based on the ArgoCD project. Application definitions, configurations, and environments are declarative and version controlled in Git. It can automatically push the desired application state into a cluster, quickly find out if the application state is in sync with the desired state, and manage applications in multi-cluster environments.
